{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7d67a9-90f2-4071-8c06-bae7bb509d9c",
   "metadata": {},
   "source": [
    "# Pandas Concepts & Practice\n",
    "\n",
    "This notebook contains my practice work and exploration of different Pandas concepts. It's designed as a learning resource for anyone interested in mastering Pandas.\n",
    "\n",
    "**Author:** Prayanshu Chourasia  \n",
    "**Date:** December 2025  \n",
    "**LinkedIn:** [Prayanshu Chourasia](https://www.linkedin.com/in/prayanshuchourasia01/)  \n",
    "**GitHub:** [Prayanshu Chourasia/AI-ML-Notebook-Hub](https://github.com/Prayanshuchourasia-01/AI-ML-Notebook-Hub)\n",
    "\n",
    "## Contents\n",
    "\n",
    "- Pandas basics\n",
    "- DataFrames and Series\n",
    "- Data manipulation\n",
    "- Data cleaning\n",
    "- Indexing and selection\n",
    "- Grouping and aggregation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook covers fundamental Pandas concepts with practical examples and exercises. It's suitable for beginners and intermediate learners.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- Pandas 1.3+\n",
    "- NumPy 1.20+\n",
    "- Jupyter Notebook\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Clone this repository\n",
    "2. Open the notebook in Jupyter\n",
    "3. Run cells in order\n",
    "4. Experiment with the code\n",
    "\n",
    "## Contact\n",
    "\n",
    "For questions or feedback, please reach out:\n",
    "\n",
    "- Email: prayanshuchourasia01@gmail.com\n",
    "- LinkedIn: [Prayanshu Chourasia](https://www.linkedin.com/in/prayanshuchourasia01/)\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** This is a learning resource. Feel free to fork, reference, or use this for educational purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a816c5-15e0-48a7-b2c4-29a819b53f0b",
   "metadata": {},
   "source": [
    "%pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81cbbd-195e-4cd4-8c54-937681c798a1",
   "metadata": {},
   "source": [
    "# Importing Pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22ca472-e87c-4809-828c-d18f5201e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843bed1-d97f-4f53-a5eb-1fb21c2ea347",
   "metadata": {},
   "source": [
    "# Read the Data from .csv file using Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b9108f-61d1-421a-b102-d5c89cbd6284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
      "0           10107               30      95.70                2  2871.00   \n",
      "1           10121               34      81.35                5  2765.90   \n",
      "2           10134               41      94.74                2  3884.34   \n",
      "3           10145               45      83.26                6  3746.70   \n",
      "4           10159               49     100.00               14  5205.27   \n",
      "...           ...              ...        ...              ...      ...   \n",
      "2818        10350               20     100.00               15  2244.40   \n",
      "2819        10373               29     100.00                1  3978.51   \n",
      "2820        10386               43     100.00                4  5417.57   \n",
      "2821        10397               34      62.24                1  2116.16   \n",
      "2822        10414               47      65.52                9  3079.44   \n",
      "\n",
      "            ORDERDATE    STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "0      2/24/2003 0:00   Shipped       1         2     2003  ...   \n",
      "1       5/7/2003 0:00   Shipped       2         5     2003  ...   \n",
      "2       7/1/2003 0:00   Shipped       3         7     2003  ...   \n",
      "3      8/25/2003 0:00   Shipped       3         8     2003  ...   \n",
      "4     10/10/2003 0:00   Shipped       4        10     2003  ...   \n",
      "...               ...       ...     ...       ...      ...  ...   \n",
      "2818   12/2/2004 0:00   Shipped       4        12     2004  ...   \n",
      "2819   1/31/2005 0:00   Shipped       1         1     2005  ...   \n",
      "2820    3/1/2005 0:00  Resolved       1         3     2005  ...   \n",
      "2821   3/28/2005 0:00   Shipped       1         3     2005  ...   \n",
      "2822    5/6/2005 0:00   On Hold       2         5     2005  ...   \n",
      "\n",
      "                       ADDRESSLINE1  ADDRESSLINE2           CITY STATE  \\\n",
      "0           897 Long Airport Avenue           NaN            NYC    NY   \n",
      "1                59 rue de l'Abbaye           NaN          Reims   NaN   \n",
      "2     27 rue du Colonel Pierre Avia           NaN          Paris   NaN   \n",
      "3                78934 Hillside Dr.           NaN       Pasadena    CA   \n",
      "4                   7734 Strong St.           NaN  San Francisco    CA   \n",
      "...                             ...           ...            ...   ...   \n",
      "2818             C/ Moralzarzal, 86           NaN         Madrid   NaN   \n",
      "2819                    Torikatu 38           NaN           Oulu   NaN   \n",
      "2820             C/ Moralzarzal, 86           NaN         Madrid   NaN   \n",
      "2821          1 rue Alsace-Lorraine           NaN       Toulouse   NaN   \n",
      "2822             8616 Spinnaker Dr.           NaN         Boston    MA   \n",
      "\n",
      "     POSTALCODE  COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
      "0         10022      USA       NaN              Yu             Kwai    Small  \n",
      "1         51100   France      EMEA         Henriot             Paul    Small  \n",
      "2         75508   France      EMEA        Da Cunha           Daniel   Medium  \n",
      "3         90003      USA       NaN           Young            Julie   Medium  \n",
      "4           NaN      USA       NaN           Brown            Julie   Medium  \n",
      "...         ...      ...       ...             ...              ...      ...  \n",
      "2818      28034    Spain      EMEA          Freyre            Diego    Small  \n",
      "2819      90110  Finland      EMEA       Koskitalo           Pirkko   Medium  \n",
      "2820      28034    Spain      EMEA          Freyre            Diego   Medium  \n",
      "2821      31000   France      EMEA          Roulet          Annette    Small  \n",
      "2822      51003      USA       NaN         Yoshido             Juri   Medium  \n",
      "\n",
      "[2823 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets\\For pandas\\sales_data_sample.csv\",encoding = \"latin1\")\n",
    "# here we use encoding = latin1 , so that computer can understand the data \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55eb056-79da-4e2c-8b7e-c69e15e58b04",
   "metadata": {},
   "source": [
    "# Read the Data from .xlsx (excel) file using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039e6bff-c87c-4948-9749-5fccc62edb12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Row ID        Order ID Order Date  Ship Date       Ship Mode  \\\n",
      "0          1  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
      "1          2  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
      "2          3  CA-2016-138688 2016-06-12 2016-06-16    Second Class   \n",
      "3          4  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
      "4          5  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
      "...      ...             ...        ...        ...             ...   \n",
      "9989    9990  CA-2014-110422 2014-01-21 2014-01-23    Second Class   \n",
      "9990    9991  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9991    9992  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9992    9993  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9993    9994  CA-2017-119914 2017-05-04 2017-05-09    Second Class   \n",
      "\n",
      "     Customer ID     Customer Name    Segment        Country             City  \\\n",
      "0       CG-12520       Claire Gute   Consumer  United States        Henderson   \n",
      "1       CG-12520       Claire Gute   Consumer  United States        Henderson   \n",
      "2       DV-13045   Darrin Van Huff  Corporate  United States      Los Angeles   \n",
      "3       SO-20335    Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
      "4       SO-20335    Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
      "...          ...               ...        ...            ...              ...   \n",
      "9989    TB-21400  Tom Boeckenhauer   Consumer  United States            Miami   \n",
      "9990    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
      "9991    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
      "9992    DB-13060       Dave Brooks   Consumer  United States       Costa Mesa   \n",
      "9993    CC-12220      Chris Cortes   Consumer  United States      Westminster   \n",
      "\n",
      "      ... Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0     ...       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1     ...       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2     ...       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3     ...       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4     ...       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "...   ...         ...     ...              ...              ...          ...   \n",
      "9989  ...       33180   South  FUR-FU-10001889        Furniture  Furnishings   \n",
      "9990  ...       92627    West  FUR-FU-10000747        Furniture  Furnishings   \n",
      "9991  ...       92627    West  TEC-PH-10003645       Technology       Phones   \n",
      "9992  ...       92627    West  OFF-PA-10004041  Office Supplies        Paper   \n",
      "9993  ...       92683    West  OFF-AP-10002684  Office Supplies   Appliances   \n",
      "\n",
      "                                           Product Name     Sales  Quantity  \\\n",
      "0                     Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1     Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2     Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3         Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                        Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "...                                                 ...       ...       ...   \n",
      "9989                             Ultra Door Pull Handle   25.2480         3   \n",
      "9990  Tenex B1-RE Series Chair Mats for Low Pile Car...   91.9600         2   \n",
      "9991                              Aastra 57i VoIP phone  258.5760         2   \n",
      "9992  It's Hot Message Books with Stickers, 2 3/4\" x 5\"   29.6000         4   \n",
      "9993  Acco 7-Outlet Masterpiece Power Center, Wihtou...  243.1600         2   \n",
      "\n",
      "      Discount    Profit  \n",
      "0         0.00   41.9136  \n",
      "1         0.00  219.5820  \n",
      "2         0.00    6.8714  \n",
      "3         0.45 -383.0310  \n",
      "4         0.20    2.5164  \n",
      "...        ...       ...  \n",
      "9989      0.20    4.1028  \n",
      "9990      0.00   15.6332  \n",
      "9991      0.20   19.3932  \n",
      "9992      0.00   13.3200  \n",
      "9993      0.00   72.9480  \n",
      "\n",
      "[9994 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"Datasets\\For pandas\\SampleSuperstore.xlsx\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610f930-a967-4757-b3c3-cb0b1f961e64",
   "metadata": {},
   "source": [
    "# Read the Data from .json file using Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e57f28-de88-4593-82b4-b79fe0b74626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                               name  \\\n",
      "0    1                                    Apple iPhone 12   \n",
      "1    2                                 Samsung Galaxy S21   \n",
      "2    3                                 Sony PlayStation 5   \n",
      "3    4                  LG OLED55CXPUA 55-inch 4K OLED TV   \n",
      "4    5        Bose QuietComfort 35 II Wireless Headphones   \n",
      "5    6                          Fitbit Versa 3 Smartwatch   \n",
      "6    7                             KitchenAid Stand Mixer   \n",
      "7    8                 Dyson V11 Absolute Cordless Vacuum   \n",
      "8    9                         Ninja Foodi Smart XL Grill   \n",
      "9   10                    Canon EOS Rebel T8i DSLR Camera   \n",
      "10  11                                  Apple AirPods Pro   \n",
      "11  12        Bose QuietComfort 35 II Wireless Headphones   \n",
      "12  13                    Fitbit Charge 4 Fitness Tracker   \n",
      "13  14                              Samsung Galaxy Watch3   \n",
      "14  15  Sony WH-1000XM4 Wireless Noise-Cancelling Head...   \n",
      "15  16          Breville Barista Express Espresso Machine   \n",
      "16  17                        Keurig K-Elite Coffee Maker   \n",
      "17  18                     iRobot Roomba i7+ Robot Vacuum   \n",
      "18  19                   Ninja Foodi Digital Air Fry Oven   \n",
      "19  20                   Cuisinart ICE-70 Ice Cream Maker   \n",
      "\n",
      "                                          description    price  \\\n",
      "0   The Apple iPhone 12 features a 6.1-inch Super ...   999.00   \n",
      "1   The Samsung Galaxy S21 features a 6.2-inch Dyn...   799.00   \n",
      "2   The Sony PlayStation 5 features an AMD Zen 2-b...   499.99   \n",
      "3   The LG OLED55CXPUA 55-inch 4K OLED TV features...  1599.99   \n",
      "4   The Bose QuietComfort 35 II Wireless Headphone...   299.00   \n",
      "5   The Fitbit Versa 3 Smartwatch features a built...   229.95   \n",
      "6   The KitchenAid Stand Mixer features a 5-quart ...   399.99   \n",
      "7   The Dyson V11 Absolute Cordless Vacuum feature...   699.99   \n",
      "8   The Ninja Foodi Smart XL Grill features 6-in-1...   279.99   \n",
      "9   The Canon EOS Rebel T8i DSLR Camera features a...   899.00   \n",
      "10  The Apple AirPods Pro feature active noise can...   249.00   \n",
      "11  The Bose QuietComfort 35 II Wireless Headphone...   299.00   \n",
      "12  The Fitbit Charge 4 Fitness Tracker features G...   129.95   \n",
      "13  The Samsung Galaxy Watch3 features a rotating ...   399.99   \n",
      "14  The Sony WH-1000XM4 Wireless Noise-Cancelling ...   349.99   \n",
      "15  The Breville Barista Express Espresso Machine ...   699.95   \n",
      "16  The Keurig K-Elite Coffee Maker features a str...   169.99   \n",
      "17  The iRobot Roomba i7+ Robot Vacuum features au...   799.99   \n",
      "18  The Ninja Foodi Digital Air Fry Oven features ...   209.99   \n",
      "19  The Cuisinart ICE-70 Ice Cream Maker features ...   139.99   \n",
      "\n",
      "           category                                              image  \n",
      "0       Electronics  https://www.apple.com/newsroom/images/product/...  \n",
      "1       Electronics  https://images.samsung.com/is/image/samsung/p6...  \n",
      "2       Electronics  https://www.sony.com/image/44baa604124b770c824...  \n",
      "3       Electronics  https://www.lg.com/us/images/tvs/md07501804/ga...  \n",
      "4       Electronics  https://assets.bose.com/content/dam/Bose_DAM/W...  \n",
      "5       Electronics  https://www.fitbit.com/global/content/dam/fitb...  \n",
      "6    Home & Kitchen  https://www.kitchenaid.com/content/dam/global/...  \n",
      "7   Home Appliances  https://www.dysoncanada.ca/dam/dyson/images/pr...  \n",
      "8    Home & Kitchen  https://www.ninjakitchen.com/medias/Ninja-OP50...  \n",
      "9       Electronics  https://www.canon.com.au/-/media/images/produc...  \n",
      "10      Electronics  https://www.apple.com/v/airpods-pro/b/images/m...  \n",
      "11      Electronics  https://assets.bose.com/content/dam/Bose_DAM/W...  \n",
      "12      Electronics  https://www.fitbit.com/global/content/dam/fitb...  \n",
      "13      Electronics  https://images.samsung.com/is/image/samsung/as...  \n",
      "14      Electronics  https://www.sony.com/image/1cdd6354c4cd21cc4f7...  \n",
      "15   Home & Kitchen  https://www.breville.com/content/dam/breville/...  \n",
      "16   Home & Kitchen  https://www.keurig.com/content/dam/global-ecom...  \n",
      "17   Home & Kitchen  https://store.irobot.com/default/i7-vacuuming-...  \n",
      "18   Home & Kitchen  https://www.ninjakitchen.com/static/img/produc...  \n",
      "19   Home & Kitchen  https://www.cuisinart.com/share/images/product...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"Datasets\\For pandas\\sample_Data.json\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacec0b-1d48-4ff6-b78e-d2d9409616bd",
   "metadata": {},
   "source": [
    "# How To Save the Data in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "476fdb78-b283-480a-86c5-c009aebf74ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Age    City\n",
      "0  Ash   12    Guna\n",
      "1  Win   15  ujjain\n",
      "2  Sad   18    hiii\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\":['Ash','Win','Sad'],\n",
    "    \"Age\":[12,15,18],\n",
    "    \"City\":['Guna','ujjain','hiii']\n",
    "}\n",
    "df = pd.DataFrame(data) # this will create the dataset of the given data. \n",
    "print(df)  \n",
    "# THen we will print the dataFrame, so then we get one more additiional column of index. \n",
    "\n",
    "df.to_csv(\"output.csv\") \n",
    "# By this to_csv() we can convert our data to csv format. #NOTE : in that csv there will be addtional column of Index. \n",
    "\n",
    "df.to_csv(\"output2.csv\",index=False) \n",
    "# By addition Index = false we can remove that additional column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c95b65-e365-4ea0-95b7-dc3bd2b55d73",
   "metadata": {},
   "source": [
    "# How to save data in the excel format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e184232-2d32-4f77-969b-92e66c7c5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Name\":['Ash','Win','Sad'],\n",
    "    \"Age\":[12,15,18],\n",
    "    \"City\":['Guna','ujjain','hiii']\n",
    "}\n",
    "df = pd.DataFrame(data) # this will create the dataset of the given data. \n",
    "print(df)  \n",
    "# THen we will print the dataFrame, so then we get one more additiional column of index. \n",
    "\n",
    "df.to_excel(\"OutExl.xlsx\");\n",
    "# To convert the Dataframe to Excel file use this cmd.\n",
    "\n",
    "df.to_excel(\"OutExl2.xlsx\",index=False) # to remove the index and convert it into the excel format we can use this.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31bf02-c7ff-4626-b64a-3c6756fb564e",
   "metadata": {},
   "source": [
    "# How to Save data in the json format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ad925-68a8-49cf-b0aa-90c88c686bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Name\":['Ash','Win','Sad'],\n",
    "    \"Age\":[12,15,18],\n",
    "    \"City\":['Guna','ujjain','hiii']\n",
    "}\n",
    "df = pd.DataFrame(data) # this will create the dataset of the given data. \n",
    "print(df)  \n",
    "# THen we will print the dataFrame, so then we get one more additiional column of index. \n",
    "\n",
    "\n",
    "df.to_json(\"OutJson.json\")      # To convert the data frame to the json format \n",
    "df.to_join(\"OutJson2.njson\",index=False) # to remove the index and convert it into the json format we can this ......\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a677d9-ae9e-47b4-8bcb-c5ead70d7000",
   "metadata": {},
   "source": [
    "# Exploring the Data using head() & tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa285e3-1c7f-406d-b42f-60ce3b611310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head Method : \n",
      "   id                                         name  \\\n",
      "0   1                              Apple iPhone 12   \n",
      "1   2                           Samsung Galaxy S21   \n",
      "2   3                           Sony PlayStation 5   \n",
      "3   4            LG OLED55CXPUA 55-inch 4K OLED TV   \n",
      "4   5  Bose QuietComfort 35 II Wireless Headphones   \n",
      "\n",
      "                                         description    price     category  \\\n",
      "0  The Apple iPhone 12 features a 6.1-inch Super ...   999.00  Electronics   \n",
      "1  The Samsung Galaxy S21 features a 6.2-inch Dyn...   799.00  Electronics   \n",
      "2  The Sony PlayStation 5 features an AMD Zen 2-b...   499.99  Electronics   \n",
      "3  The LG OLED55CXPUA 55-inch 4K OLED TV features...  1599.99  Electronics   \n",
      "4  The Bose QuietComfort 35 II Wireless Headphone...   299.00  Electronics   \n",
      "\n",
      "                                               image  \n",
      "0  https://www.apple.com/newsroom/images/product/...  \n",
      "1  https://images.samsung.com/is/image/samsung/p6...  \n",
      "2  https://www.sony.com/image/44baa604124b770c824...  \n",
      "3  https://www.lg.com/us/images/tvs/md07501804/ga...  \n",
      "4  https://assets.bose.com/content/dam/Bose_DAM/W...  \n",
      "   id                                         name  \\\n",
      "0   1                              Apple iPhone 12   \n",
      "1   2                           Samsung Galaxy S21   \n",
      "2   3                           Sony PlayStation 5   \n",
      "3   4            LG OLED55CXPUA 55-inch 4K OLED TV   \n",
      "4   5  Bose QuietComfort 35 II Wireless Headphones   \n",
      "5   6                    Fitbit Versa 3 Smartwatch   \n",
      "6   7                       KitchenAid Stand Mixer   \n",
      "7   8           Dyson V11 Absolute Cordless Vacuum   \n",
      "8   9                   Ninja Foodi Smart XL Grill   \n",
      "9  10              Canon EOS Rebel T8i DSLR Camera   \n",
      "\n",
      "                                         description    price  \\\n",
      "0  The Apple iPhone 12 features a 6.1-inch Super ...   999.00   \n",
      "1  The Samsung Galaxy S21 features a 6.2-inch Dyn...   799.00   \n",
      "2  The Sony PlayStation 5 features an AMD Zen 2-b...   499.99   \n",
      "3  The LG OLED55CXPUA 55-inch 4K OLED TV features...  1599.99   \n",
      "4  The Bose QuietComfort 35 II Wireless Headphone...   299.00   \n",
      "5  The Fitbit Versa 3 Smartwatch features a built...   229.95   \n",
      "6  The KitchenAid Stand Mixer features a 5-quart ...   399.99   \n",
      "7  The Dyson V11 Absolute Cordless Vacuum feature...   699.99   \n",
      "8  The Ninja Foodi Smart XL Grill features 6-in-1...   279.99   \n",
      "9  The Canon EOS Rebel T8i DSLR Camera features a...   899.00   \n",
      "\n",
      "          category                                              image  \n",
      "0      Electronics  https://www.apple.com/newsroom/images/product/...  \n",
      "1      Electronics  https://images.samsung.com/is/image/samsung/p6...  \n",
      "2      Electronics  https://www.sony.com/image/44baa604124b770c824...  \n",
      "3      Electronics  https://www.lg.com/us/images/tvs/md07501804/ga...  \n",
      "4      Electronics  https://assets.bose.com/content/dam/Bose_DAM/W...  \n",
      "5      Electronics  https://www.fitbit.com/global/content/dam/fitb...  \n",
      "6   Home & Kitchen  https://www.kitchenaid.com/content/dam/global/...  \n",
      "7  Home Appliances  https://www.dysoncanada.ca/dam/dyson/images/pr...  \n",
      "8   Home & Kitchen  https://www.ninjakitchen.com/medias/Ninja-OP50...  \n",
      "9      Electronics  https://www.canon.com.au/-/media/images/produc...  \n",
      "Tail Method : \n",
      "    id                                       name  \\\n",
      "15  16  Breville Barista Express Espresso Machine   \n",
      "16  17                Keurig K-Elite Coffee Maker   \n",
      "17  18             iRobot Roomba i7+ Robot Vacuum   \n",
      "18  19           Ninja Foodi Digital Air Fry Oven   \n",
      "19  20           Cuisinart ICE-70 Ice Cream Maker   \n",
      "\n",
      "                                          description   price        category  \\\n",
      "15  The Breville Barista Express Espresso Machine ...  699.95  Home & Kitchen   \n",
      "16  The Keurig K-Elite Coffee Maker features a str...  169.99  Home & Kitchen   \n",
      "17  The iRobot Roomba i7+ Robot Vacuum features au...  799.99  Home & Kitchen   \n",
      "18  The Ninja Foodi Digital Air Fry Oven features ...  209.99  Home & Kitchen   \n",
      "19  The Cuisinart ICE-70 Ice Cream Maker features ...  139.99  Home & Kitchen   \n",
      "\n",
      "                                                image  \n",
      "15  https://www.breville.com/content/dam/breville/...  \n",
      "16  https://www.keurig.com/content/dam/global-ecom...  \n",
      "17  https://store.irobot.com/default/i7-vacuuming-...  \n",
      "18  https://www.ninjakitchen.com/static/img/produc...  \n",
      "19  https://www.cuisinart.com/share/images/product...  \n",
      "    id                                               name  \\\n",
      "10  11                                  Apple AirPods Pro   \n",
      "11  12        Bose QuietComfort 35 II Wireless Headphones   \n",
      "12  13                    Fitbit Charge 4 Fitness Tracker   \n",
      "13  14                              Samsung Galaxy Watch3   \n",
      "14  15  Sony WH-1000XM4 Wireless Noise-Cancelling Head...   \n",
      "15  16          Breville Barista Express Espresso Machine   \n",
      "16  17                        Keurig K-Elite Coffee Maker   \n",
      "17  18                     iRobot Roomba i7+ Robot Vacuum   \n",
      "18  19                   Ninja Foodi Digital Air Fry Oven   \n",
      "19  20                   Cuisinart ICE-70 Ice Cream Maker   \n",
      "\n",
      "                                          description   price        category  \\\n",
      "10  The Apple AirPods Pro feature active noise can...  249.00     Electronics   \n",
      "11  The Bose QuietComfort 35 II Wireless Headphone...  299.00     Electronics   \n",
      "12  The Fitbit Charge 4 Fitness Tracker features G...  129.95     Electronics   \n",
      "13  The Samsung Galaxy Watch3 features a rotating ...  399.99     Electronics   \n",
      "14  The Sony WH-1000XM4 Wireless Noise-Cancelling ...  349.99     Electronics   \n",
      "15  The Breville Barista Express Espresso Machine ...  699.95  Home & Kitchen   \n",
      "16  The Keurig K-Elite Coffee Maker features a str...  169.99  Home & Kitchen   \n",
      "17  The iRobot Roomba i7+ Robot Vacuum features au...  799.99  Home & Kitchen   \n",
      "18  The Ninja Foodi Digital Air Fry Oven features ...  209.99  Home & Kitchen   \n",
      "19  The Cuisinart ICE-70 Ice Cream Maker features ...  139.99  Home & Kitchen   \n",
      "\n",
      "                                                image  \n",
      "10  https://www.apple.com/v/airpods-pro/b/images/m...  \n",
      "11  https://assets.bose.com/content/dam/Bose_DAM/W...  \n",
      "12  https://www.fitbit.com/global/content/dam/fitb...  \n",
      "13  https://images.samsung.com/is/image/samsung/as...  \n",
      "14  https://www.sony.com/image/1cdd6354c4cd21cc4f7...  \n",
      "15  https://www.breville.com/content/dam/breville/...  \n",
      "16  https://www.keurig.com/content/dam/global-ecom...  \n",
      "17  https://store.irobot.com/default/i7-vacuuming-...  \n",
      "18  https://www.ninjakitchen.com/static/img/produc...  \n",
      "19  https://www.cuisinart.com/share/images/product...  \n"
     ]
    }
   ],
   "source": [
    "# head(n) ---> it returns the first n rows of the Dataset , and if n is not provided then by default it returns 5 rows \n",
    "# tail(n) ---> it returns the last n rows of the dataset , and if n is not provided then by default it returns 5 rows \n",
    "\n",
    "df = pd.read_json(\"Datasets\\For pandas\\sample_Data.json\")\n",
    "print(\"Head Method : \")\n",
    "print(df.head())    # it will return only first 5  rows \n",
    "print(df.head(10))  # it will return n(10) first rows \n",
    "\n",
    "print(\"Tail Method : \")\n",
    "print(df.tail())   # it will return bottom 5 rows \n",
    "print(df.tail(10)) # it will return bottom 10 rows \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00431087-24ab-4738-9875-a351b117762f",
   "metadata": {},
   "source": [
    "# Understanding data using info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0893ef99-2ee5-43fc-93b7-6b582c0be4b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           20 non-null     int64  \n",
      " 1   name         20 non-null     object \n",
      " 2   description  20 non-null     object \n",
      " 3   price        20 non-null     float64\n",
      " 4   category     20 non-null     object \n",
      " 5   image        20 non-null     object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# info() method ---> tells you about the number of row and column your dataset have , column names and the type of data those column are storing , \n",
    "# and also tells that if there is any missing value is there in the dataset of any column or not , and the menory usage of the data frame. \n",
    "\n",
    "df = pd.read_json(\"Datasets\\For pandas\\sample_Data.json\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e4ccde-0f20-482a-bbfa-54dd63983878",
   "metadata": {},
   "source": [
    "# To summary of the descriptive Statistics using describe() method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23ce096-7e94-41ba-a99e-c62e13cebbde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ORDERNUMBER  QUANTITYORDERED    PRICEEACH  ORDERLINENUMBER  \\\n",
      "count   2823.000000      2823.000000  2823.000000      2823.000000   \n",
      "mean   10258.725115        35.092809    83.658544         6.466171   \n",
      "std       92.085478         9.741443    20.174277         4.225841   \n",
      "min    10100.000000         6.000000    26.880000         1.000000   \n",
      "25%    10180.000000        27.000000    68.860000         3.000000   \n",
      "50%    10262.000000        35.000000    95.700000         6.000000   \n",
      "75%    10333.500000        43.000000   100.000000         9.000000   \n",
      "max    10425.000000        97.000000   100.000000        18.000000   \n",
      "\n",
      "              SALES       QTR_ID     MONTH_ID     YEAR_ID         MSRP  \n",
      "count   2823.000000  2823.000000  2823.000000  2823.00000  2823.000000  \n",
      "mean    3553.889072     2.717676     7.092455  2003.81509   100.715551  \n",
      "std     1841.865106     1.203878     3.656633     0.69967    40.187912  \n",
      "min      482.130000     1.000000     1.000000  2003.00000    33.000000  \n",
      "25%     2203.430000     2.000000     4.000000  2003.00000    68.000000  \n",
      "50%     3184.800000     3.000000     8.000000  2004.00000    99.000000  \n",
      "75%     4508.000000     4.000000    11.000000  2004.00000   124.000000  \n",
      "max    14082.800000     4.000000    12.000000  2005.00000   214.000000  \n"
     ]
    }
   ],
   "source": [
    "# describe() ---->  a Summary of descriptive statistics for numerical columns in the dataframe.\n",
    "\n",
    "df = pd.read_csv(\"Datasets\\For pandas\\sales_data_sample.csv\",encoding=\"latin1\")\n",
    "\n",
    "print(df.describe()) # This method gives us the statistics things , like mean,std(standard deviation) , min,max,25% .... \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f081e0-8943-46aa-93ca-3667518bde9a",
   "metadata": {},
   "source": [
    "# Using Shapes & Column attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2287b98e-ff22-4869-942b-9d28f4c3a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (2823, 25)\n",
      "Column : Index(['ORDERNUMBER', 'QUANTITYORDERED', 'PRICEEACH', 'ORDERLINENUMBER',\n",
      "       'SALES', 'ORDERDATE', 'STATUS', 'QTR_ID', 'MONTH_ID', 'YEAR_ID',\n",
      "       'PRODUCTLINE', 'MSRP', 'PRODUCTCODE', 'CUSTOMERNAME', 'PHONE',\n",
      "       'ADDRESSLINE1', 'ADDRESSLINE2', 'CITY', 'STATE', 'POSTALCODE',\n",
      "       'COUNTRY', 'TERRITORY', 'CONTACTLASTNAME', 'CONTACTFIRSTNAME',\n",
      "       'DEALSIZE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets\\For pandas\\sales_data_sample.csv\",encoding= \"latin1\")\n",
    "\n",
    "print(f\"Shape : {df.shape}\") # it returns the 2 values in a tuple (rows,columns) \n",
    "print(f\"Column : {df.columns}\") # it returns the names of the columns in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794acb4-ba7a-4c8a-bf66-a5f76eb55e11",
   "metadata": {},
   "source": [
    "# Selecting Specfic Columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d264e1ac-57b5-495c-8ff3-ded632c3477c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                 NYC\n",
      "1               Reims\n",
      "2               Paris\n",
      "3            Pasadena\n",
      "4       San Francisco\n",
      "            ...      \n",
      "2818           Madrid\n",
      "2819             Oulu\n",
      "2820           Madrid\n",
      "2821         Toulouse\n",
      "2822           Boston\n",
      "Name: CITY, Length: 2823, dtype: object\n",
      "\n",
      "\n",
      "0       2871.00\n",
      "1       2765.90\n",
      "2       3884.34\n",
      "3       3746.70\n",
      "4       5205.27\n",
      "         ...   \n",
      "2818    2244.40\n",
      "2819    3978.51\n",
      "2820    5417.57\n",
      "2821    2116.16\n",
      "2822    3079.44\n",
      "Name: SALES, Length: 2823, dtype: float64\n",
      "               CITY    SALES\n",
      "0               NYC  2871.00\n",
      "1             Reims  2765.90\n",
      "2             Paris  3884.34\n",
      "3          Pasadena  3746.70\n",
      "4     San Francisco  5205.27\n",
      "...             ...      ...\n",
      "2818         Madrid  2244.40\n",
      "2819           Oulu  3978.51\n",
      "2820         Madrid  5417.57\n",
      "2821       Toulouse  2116.16\n",
      "2822         Boston  3079.44\n",
      "\n",
      "[2823 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"Datasets\\For pandas/sales_data_sample.csv\",encoding=\"latin1\")\n",
    "\n",
    "#print(df)\n",
    "# select Specific column\n",
    "\n",
    "city = df[\"CITY\"]\n",
    "print(city)\n",
    "print(\"\\n\")\n",
    "print(df[\"SALES\"])\n",
    "\n",
    "# selection multiple columns \n",
    "subset = df[[\"CITY\",\"SALES\"]]\n",
    "print(subset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e5684-83a1-45a0-867c-b494914b5bf2",
   "metadata": {},
   "source": [
    "#  Filtering of Rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc939db-b73f-4e81-be9b-fbd3779273d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
      "30          10150               45      100.0                8  10993.5   \n",
      "43          10304               47      100.0                6  10172.7   \n",
      "44          10312               48      100.0                3  11623.7   \n",
      "53          10424               50      100.0                6  12001.0   \n",
      "104         10403               66      100.0                9  11886.6   \n",
      "188         10127               46      100.0                2  11279.2   \n",
      "198         10247               44      100.0                2  10606.2   \n",
      "598         10407               76      100.0                2  14082.8   \n",
      "744         10322               50      100.0                6  12536.5   \n",
      "1062        10412               60      100.0                9  11887.8   \n",
      "1133        10333               46      100.0                2  11336.7   \n",
      "1188        10406               65      100.0                1  10468.9   \n",
      "1839        10339               55      100.0               13  10758.0   \n",
      "1995        10405               76      100.0                3  11739.7   \n",
      "2117        10375               43      100.0                2  10039.6   \n",
      "2505        10388               46      100.0                2  10066.6   \n",
      "\n",
      "            ORDERDATE      STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "30     9/19/2003 0:00     Shipped       3         9     2003  ...   \n",
      "43    10/11/2004 0:00     Shipped       4        10     2004  ...   \n",
      "44    10/21/2004 0:00     Shipped       4        10     2004  ...   \n",
      "53     5/31/2005 0:00  In Process       2         5     2005  ...   \n",
      "104     4/8/2005 0:00     Shipped       2         4     2005  ...   \n",
      "188     6/3/2003 0:00     Shipped       2         6     2003  ...   \n",
      "198     5/5/2004 0:00     Shipped       2         5     2004  ...   \n",
      "598    4/22/2005 0:00     On Hold       2         4     2005  ...   \n",
      "744    11/4/2004 0:00     Shipped       4        11     2004  ...   \n",
      "1062    5/3/2005 0:00     Shipped       2         5     2005  ...   \n",
      "1133  11/18/2004 0:00     Shipped       4        11     2004  ...   \n",
      "1188   4/15/2005 0:00    Disputed       2         4     2005  ...   \n",
      "1839  11/23/2004 0:00     Shipped       4        11     2004  ...   \n",
      "1995   4/14/2005 0:00     Shipped       2         4     2005  ...   \n",
      "2117    2/3/2005 0:00     Shipped       1         2     2005  ...   \n",
      "2505    3/3/2005 0:00     Shipped       1         3     2005  ...   \n",
      "\n",
      "                              ADDRESSLINE1  ADDRESSLINE2           CITY  \\\n",
      "30    Bronz Sok., Bronz Apt. 3/6 Tesvikiye           NaN      Singapore   \n",
      "43                  67, avenue de l'Europe           NaN     Versailles   \n",
      "44                         5677 Strong St.           NaN     San Rafael   \n",
      "53                      C/ Moralzarzal, 86           NaN         Madrid   \n",
      "104           Berkeley Gardens 12  Brewery           NaN      Liverpool   \n",
      "188                      4092 Furth Circle     Suite 400            NYC   \n",
      "198    Software Engineering Center, SEC Oy           NaN          Espoo   \n",
      "598                         3086 Ingle Ln.           NaN       San Jose   \n",
      "744               2304 Long Airport Avenue           NaN         Nashua   \n",
      "1062                    C/ Moralzarzal, 86           NaN         Madrid   \n",
      "1133             5557 North Pendale Street           NaN  San Francisco   \n",
      "1188                          Vinb'ltet 34           NaN      Kobenhavn   \n",
      "1839                        2-2-8 Roppongi           NaN      Minato-ku   \n",
      "1995                      24, place Kluber           NaN     Strasbourg   \n",
      "2117          67, rue des Cinquante Otages           NaN         Nantes   \n",
      "2505                     1785 First Street           NaN    New Bedford   \n",
      "\n",
      "      STATE POSTALCODE    COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME  \\\n",
      "30      NaN      79903  Singapore     Japan       Natividad             Eric   \n",
      "43      NaN      78000     France      EMEA          Tonini           Daniel   \n",
      "44       CA      97562        USA       NaN          Nelson          Valarie   \n",
      "53      NaN      28034      Spain      EMEA          Freyre            Diego   \n",
      "104     NaN    WX1 6LT         UK      EMEA           Devon        Elizabeth   \n",
      "188      NY      10022        USA       NaN           Young             Jeff   \n",
      "198     NaN  FIN-02271    Finland      EMEA        Suominen            Kalle   \n",
      "598      CA      94217        USA       NaN           Frick              Sue   \n",
      "744      NH      62005        USA       NaN           Young          Valarie   \n",
      "1062    NaN      28034      Spain      EMEA          Freyre            Diego   \n",
      "1133     CA        NaN        USA       NaN          Murphy            Julie   \n",
      "1188    NaN       1734    Denmark      EMEA        Petersen            Jytte   \n",
      "1839  Tokyo   106-0032      Japan     Japan       Shimamura            Akiko   \n",
      "1995    NaN      67000     France      EMEA         Citeaux       Frederique   \n",
      "2117    NaN      44000     France      EMEA         Labrune           Janine   \n",
      "2505     MA      50553        USA       NaN         Benitez          Violeta   \n",
      "\n",
      "     DEALSIZE  \n",
      "30      Large  \n",
      "43      Large  \n",
      "44      Large  \n",
      "53      Large  \n",
      "104     Large  \n",
      "188     Large  \n",
      "198     Large  \n",
      "598     Large  \n",
      "744     Large  \n",
      "1062    Large  \n",
      "1133    Large  \n",
      "1188    Large  \n",
      "1839    Large  \n",
      "1995    Large  \n",
      "2117    Large  \n",
      "2505    Large  \n",
      "\n",
      "[16 rows x 25 columns]\n",
      "      ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
      "104         10403               66      100.0                9  11886.6   \n",
      "598         10407               76      100.0                2  14082.8   \n",
      "1062        10412               60      100.0                9  11887.8   \n",
      "1188        10406               65      100.0                1  10468.9   \n",
      "1839        10339               55      100.0               13  10758.0   \n",
      "1995        10405               76      100.0                3  11739.7   \n",
      "\n",
      "            ORDERDATE    STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "104     4/8/2005 0:00   Shipped       2         4     2005  ...   \n",
      "598    4/22/2005 0:00   On Hold       2         4     2005  ...   \n",
      "1062    5/3/2005 0:00   Shipped       2         5     2005  ...   \n",
      "1188   4/15/2005 0:00  Disputed       2         4     2005  ...   \n",
      "1839  11/23/2004 0:00   Shipped       4        11     2004  ...   \n",
      "1995   4/14/2005 0:00   Shipped       2         4     2005  ...   \n",
      "\n",
      "                      ADDRESSLINE1  ADDRESSLINE2        CITY  STATE  \\\n",
      "104   Berkeley Gardens 12  Brewery           NaN   Liverpool    NaN   \n",
      "598                 3086 Ingle Ln.           NaN    San Jose     CA   \n",
      "1062            C/ Moralzarzal, 86           NaN      Madrid    NaN   \n",
      "1188                  Vinb'ltet 34           NaN   Kobenhavn    NaN   \n",
      "1839                2-2-8 Roppongi           NaN   Minato-ku  Tokyo   \n",
      "1995              24, place Kluber           NaN  Strasbourg    NaN   \n",
      "\n",
      "     POSTALCODE  COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
      "104     WX1 6LT       UK      EMEA           Devon        Elizabeth    Large  \n",
      "598       94217      USA       NaN           Frick              Sue    Large  \n",
      "1062      28034    Spain      EMEA          Freyre            Diego    Large  \n",
      "1188       1734  Denmark      EMEA        Petersen            Jytte    Large  \n",
      "1839   106-0032    Japan     Japan       Shimamura            Akiko    Large  \n",
      "1995      67000   France      EMEA         Citeaux       Frederique    Large  \n",
      "\n",
      "[6 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets\\For pandas/sales_data_sample.csv\",encoding=\"latin1\")\n",
    "\n",
    "#print(df)\n",
    "\n",
    "# filter rows \n",
    "high_sales = df[df[\"SALES\"]>10000]\n",
    "print(high_sales)\n",
    "\n",
    "# Filtering Rows  based on the multiple conditons \n",
    "\n",
    "multiFilter = df[(df[\"SALES\"]>10000) & (df[\"QUANTITYORDERED\"]>50)]\n",
    "print(multiFilter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6728a-89b2-4f64-830c-3044d6c5655e",
   "metadata": {},
   "source": [
    "# Working with OR conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ded53af-5589-4966-a7be-6d48ab66ebd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER     SALES  \\\n",
      "30          10150               45     100.00                8  10993.50   \n",
      "39          10258               32     100.00                6   7680.64   \n",
      "43          10304               47     100.00                6  10172.70   \n",
      "44          10312               48     100.00                3  11623.70   \n",
      "53          10424               50     100.00                6  12001.00   \n",
      "...           ...              ...        ...              ...       ...   \n",
      "2647        10210               25     100.00                6   2818.00   \n",
      "2672        10210               31      86.40               13   2678.40   \n",
      "2751        10210               42      70.33               15   2953.86   \n",
      "2762        10339               50      57.86                8   2893.00   \n",
      "2789        10339               27      76.31                6   2060.37   \n",
      "\n",
      "            ORDERDATE      STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "30     9/19/2003 0:00     Shipped       3         9     2003  ...   \n",
      "39     6/15/2004 0:00     Shipped       2         6     2004  ...   \n",
      "43    10/11/2004 0:00     Shipped       4        10     2004  ...   \n",
      "44    10/21/2004 0:00     Shipped       4        10     2004  ...   \n",
      "53     5/31/2005 0:00  In Process       2         5     2005  ...   \n",
      "...               ...         ...     ...       ...      ...  ...   \n",
      "2647   1/12/2004 0:00     Shipped       1         1     2004  ...   \n",
      "2672   1/12/2004 0:00     Shipped       1         1     2004  ...   \n",
      "2751   1/12/2004 0:00     Shipped       1         1     2004  ...   \n",
      "2762  11/23/2004 0:00     Shipped       4        11     2004  ...   \n",
      "2789  11/23/2004 0:00     Shipped       4        11     2004  ...   \n",
      "\n",
      "                                  ADDRESSLINE1  ADDRESSLINE2        CITY  \\\n",
      "30        Bronz Sok., Bronz Apt. 3/6 Tesvikiye           NaN   Singapore   \n",
      "39                              2-2-8 Roppongi           NaN   Minato-ku   \n",
      "43                      67, avenue de l'Europe           NaN  Versailles   \n",
      "44                             5677 Strong St.           NaN  San Rafael   \n",
      "53                          C/ Moralzarzal, 86           NaN      Madrid   \n",
      "...                                        ...           ...         ...   \n",
      "2647  Dojima Avanza 4F, 1-6-20 Dojima, Kita-ku           NaN       Osaka   \n",
      "2672  Dojima Avanza 4F, 1-6-20 Dojima, Kita-ku           NaN       Osaka   \n",
      "2751  Dojima Avanza 4F, 1-6-20 Dojima, Kita-ku           NaN       Osaka   \n",
      "2762                            2-2-8 Roppongi           NaN   Minato-ku   \n",
      "2789                            2-2-8 Roppongi           NaN   Minato-ku   \n",
      "\n",
      "      STATE POSTALCODE    COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME  \\\n",
      "30      NaN      79903  Singapore     Japan       Natividad             Eric   \n",
      "39    Tokyo   106-0032      Japan     Japan       Shimamura            Akiko   \n",
      "43      NaN      78000     France      EMEA          Tonini           Daniel   \n",
      "44       CA      97562        USA       NaN          Nelson          Valarie   \n",
      "53      NaN      28034      Spain      EMEA          Freyre            Diego   \n",
      "...     ...        ...        ...       ...             ...              ...   \n",
      "2647  Osaka   530-0003      Japan     Japan         Kentary             Mory   \n",
      "2672  Osaka   530-0003      Japan     Japan         Kentary             Mory   \n",
      "2751  Osaka   530-0003      Japan     Japan         Kentary             Mory   \n",
      "2762  Tokyo   106-0032      Japan     Japan       Shimamura            Akiko   \n",
      "2789  Tokyo   106-0032      Japan     Japan       Shimamura            Akiko   \n",
      "\n",
      "     DEALSIZE  \n",
      "30      Large  \n",
      "39      Large  \n",
      "43      Large  \n",
      "44      Large  \n",
      "53      Large  \n",
      "...       ...  \n",
      "2647    Small  \n",
      "2672    Small  \n",
      "2751    Small  \n",
      "2762    Small  \n",
      "2789    Small  \n",
      "\n",
      "[67 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets\\For pandas/sales_data_sample.csv\",encoding=\"latin1\")\n",
    "\n",
    "# print(df)\n",
    "\n",
    "\n",
    "# OR condtion : says that either any of the conditio gets true we will get the result. \n",
    "eitherFilter = df[(df[\"SALES\"]>10000) | (df[\"COUNTRY\"]==\"Japan\")]\n",
    "print(eitherFilter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b18ac4-e5da-4d55-b7f1-c147f83a2c3a",
   "metadata": {},
   "source": [
    "# Advance Pandas Funcitons \n",
    "## Adding Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6908b4a1-72c9-4256-a84f-57fee9c69e42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name Age  Salary  Performance_Score   Bonus\n",
      "0    A   1   50000                 65  5000.0\n",
      "1    B   2   30000                 89  3000.0\n",
      "2    C   3   20000                 62  2000.0\n",
      "3    D   4   40000                 78  4000.0\n",
      "4    E   5   60000                 98  6000.0\n",
      "5    F   6   70000                 21  7000.0\n",
      "   Index Name Age  Salary  Performance_Score   Bonus\n",
      "0      1    A   1   50000                 65  5000.0\n",
      "1      2    B   2   30000                 89  3000.0\n",
      "2      3    C   3   20000                 62  2000.0\n",
      "3      4    D   4   40000                 78  4000.0\n",
      "4      5    E   5   60000                 98  6000.0\n",
      "5      6    F   6   70000                 21  7000.0\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\" : ['A','B','C','D','E','F'],\n",
    "    \"Age\" : ['1','2','3','4','5','6'],\n",
    "    \"Salary\" : [50000,30000,20000,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , 78, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "# print(df)\n",
    "\n",
    "# We have two methods to do this work.\n",
    "# 1st --> using square brackets method df[\"column name\"] = values or data of the columns\n",
    "\n",
    "\n",
    "df[\"Bonus\"] = df[\"Salary\"] * 0.1  # 10% increaing  \n",
    "#     df[\"Bonus\"] = [100,200,300,400,500,600] ----> we can also do this \n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd --> using the insert() method to insert the column at the specific position\n",
    "# df.insert(loc, \"Column_name\" ,Some_data) \n",
    "\n",
    "df.insert(0,\"Index\", [1,2,3,4,5,6])\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7f426-5f56-4639-8da8-0716ab0c22e2",
   "metadata": {},
   "source": [
    "# Updating value in a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bede5c5f-319c-4f1a-a74b-9a5a06cb4cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name Age  Salary  Performance_Score\n",
      "0    A   1   50000                 65\n",
      "1    B   2   30000                 89\n",
      "2    C   3   20000                 62\n",
      "3    D   4   40000                 78\n",
      "4    E   5   60000                 98\n",
      "5    F   6   70000                 21\n",
      "  Name Age  Salary  Performance_Score\n",
      "0    A   1     200                 65\n",
      "1    B   2   30000                 89\n",
      "2    C   3   20000                 62\n",
      "3    D   4   40000                 78\n",
      "4    E   5   60000                 98\n",
      "5    F   6   70000                 21\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\" : ['A','B','C','D','E','F'],\n",
    "    \"Age\" : ['1','2','3','4','5','6'],\n",
    "    \"Salary\" : [50000,30000,20000,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , 78, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "#   .loc[] ---> it is a method of pandas\n",
    "\n",
    "# For Specific value of the Data Frame.\n",
    "# df.loc[row index , \"column name \"] = new value \n",
    "df.loc[0,\"Salary\"] = 200\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b911fd-8429-4503-91b0-c2f3b151eceb",
   "metadata": {},
   "source": [
    "# Updating Whole Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75201627-862f-4b2a-972b-d4773d60fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name Age  Salary  Performance_Score\n",
      "0    A   1   50000                 65\n",
      "1    B   2   30000                 89\n",
      "2    C   3   20000                 62\n",
      "3    D   4   40000                 78\n",
      "4    E   5   60000                 98\n",
      "5    F   6   70000                 21\n",
      "  Name Age   Salary  Performance_Score\n",
      "0    A   1  52500.0                 65\n",
      "1    B   2  31500.0                 89\n",
      "2    C   3  21000.0                 62\n",
      "3    D   4  42000.0                 78\n",
      "4    E   5  63000.0                 98\n",
      "5    F   6  73500.0                 21\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\" : ['A','B','C','D','E','F'],\n",
    "    \"Age\" : ['1','2','3','4','5','6'],\n",
    "    \"Salary\" : [50000,30000,20000,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , 78, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df) \n",
    "\n",
    "df[\"Salary\"] = df[\"Salary\"]*1.05\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1678cc-72bc-42b6-8e4a-a0459c886824",
   "metadata": {},
   "source": [
    "# Removing Columns from the DataFrame using drop() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eebbb6d-8569-4914-a75e-8c4ac450cc6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name Age  Salary\n",
      "0    A   1   50000\n",
      "1    B   2   30000\n",
      "2    C   3   20000\n",
      "3    D   4   40000\n",
      "4    E   5   60000\n",
      "5    F   6   70000\n",
      "Double : \n",
      "  Name\n",
      "0    A\n",
      "1    B\n",
      "2    C\n",
      "3    D\n",
      "4    E\n",
      "5    F\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\" : ['A','B','C','D','E','F'],\n",
    "    \"Age\" : ['1','2','3','4','5','6'],\n",
    "    \"Salary\" : [50000,30000,20000,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , 78, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "# df.drop(columns = [\"ColumnName\"],inplace=true)   here inplace = true means it will change directly in the orifinal dataset\n",
    "# if we put inplace = false , there it will return a new dataset.\n",
    "df.drop(columns=[\"Performance_Score\"],inplace = True) # For removing single columns\n",
    "print(df)\n",
    "print(\"Double : \")\n",
    "df.drop(columns=[\"Age\",\"Salary\"],inplace=True) # For Removing multiple columns \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa2ff11-df1f-4e93-b319-df655db50761",
   "metadata": {},
   "source": [
    "# Decting/Identifing the Missing Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655a82b7-1c84-4af8-bf04-0a35c311cd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary  Performance_Score\n",
      "0     A     1  50000.0               65.0\n",
      "1  None     2  30000.0               89.0\n",
      "2     C     3      NaN               62.0\n",
      "3     D  None  40000.0                NaN\n",
      "4     E     5  60000.0               98.0\n",
      "5     F     6  70000.0               21.0\n",
      "    Name    Age  Salary  Performance_Score\n",
      "0  False  False   False              False\n",
      "1   True  False   False              False\n",
      "2  False  False    True              False\n",
      "3  False   True   False               True\n",
      "4  False  False   False              False\n",
      "5  False  False   False              False\n",
      "Name                 1\n",
      "Age                  1\n",
      "Salary               1\n",
      "Performance_Score    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The missing data is represented as NAN[not a number] and none [For Object data type ]\n",
    "\n",
    "# To Detect/identify where is missing data , we have a method ---> isnull() it returns a bool dataframe in which \n",
    "# True means [value is missing ] , False means [value is present]\n",
    "\n",
    "data = {\n",
    "    \"Name\" : ['A',None,'C','D','E','F'],\n",
    "    \"Age\" : ['1','2','3',None,'5','6'],\n",
    "    \"Salary\" : [50000,30000,None,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , None, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# isnull()\n",
    "\n",
    "print(df.isnull()) # to find out where is the missing values \n",
    "print(df.isnull().sum()) # This is To find how many missing values are.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e592c27c-094e-4ce4-b0d0-1626ba1a1495",
   "metadata": {},
   "source": [
    "# Handing Missing Data  --- using dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02faf195-4b95-4134-b3a8-c3ab8f8a15d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary  Performance_Score\n",
      "0     A     1  50000.0               65.0\n",
      "1  None     2  30000.0               89.0\n",
      "2     C     3      NaN               62.0\n",
      "3     D  None  40000.0                NaN\n",
      "4     E     5  60000.0               98.0\n",
      "5     F     6  70000.0               21.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# if any row or columns is not important and dont matters in the result of your program then its better we remove the whole either the column or row\n",
    "# For that we use ---> df.dropna(axis=0,inplace=True) axis = 0 means row , axis = 1 means column , and inpalce true means change in original dataset\n",
    "\n",
    "data = {\n",
    "    \"Name\" : ['A',None,'C','D','E','F'],\n",
    "    \"Age\" : ['1','2','3',None,'5','6'],\n",
    "    \"Salary\" : [50000,30000,None,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , None, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "# print(df.dropna(axis=0,inplace=True)) AXIS=0 works in rows , AXIS=1 works in COlumns \n",
    "print(df.dropna(inplace=True))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f1d510-b622-4b4b-b1ca-3df0667d6314",
   "metadata": {},
   "source": [
    "# Handing Missing Data by filling data --- using fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ef52b07-6bca-45c8-89df-9b8bc2db7555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   Age   Salary  Performance_Score\n",
      "0     A     1  50000.0               65.0\n",
      "1  None     2  30000.0               89.0\n",
      "2     C     3      NaN               62.0\n",
      "3     D  None  40000.0                NaN\n",
      "4     E     5  60000.0               98.0\n",
      "5     F     6  70000.0               21.0\n",
      "Updated DataFrame\n",
      "  Name Age   Salary  Performance_Score\n",
      "0    A   1  50000.0               65.0\n",
      "1    0   2  30000.0               89.0\n",
      "2    C   3      0.0               62.0\n",
      "3    D   0  40000.0                0.0\n",
      "4    E   5  60000.0               98.0\n",
      "5    F   6  70000.0               21.0\n"
     ]
    }
   ],
   "source": [
    "#fillna(value,inplace=True)\n",
    "data = {\n",
    "    \"Name\" : ['A',None,'C','D','E','F'],\n",
    "    \"Age\" : ['1','2','3',None,'5','6'],\n",
    "    \"Salary\" : [50000,30000,None,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , None, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(\"Updated DataFrame\")\n",
    "df.fillna(0,inplace=True) # here we change the original dataset, adn replaced allt he missing values with 0.\n",
    "print(df)\n",
    "# NOTE we only use default values here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491adfb2-81ba-4c0c-a20a-9f2b4f61cfd3",
   "metadata": {},
   "source": [
    "# Handing Missing Data by filling calculated data --- using fillna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3436f9fd-a1a0-4939-9733-50e686507aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age   Salary  Performance_Score\n",
      "0     A  1.0  50000.0               65.0\n",
      "1  None  2.0  30000.0               89.0\n",
      "2     C  3.0      NaN               62.0\n",
      "3     D  NaN  40000.0                NaN\n",
      "4     E  5.0  60000.0               98.0\n",
      "5     F  6.0  70000.0               21.0\n",
      "Updated DataFrame\n",
      "   Name  Age   Salary  Performance_Score\n",
      "0     A  1.0  50000.0               65.0\n",
      "1  None  2.0  30000.0               89.0\n",
      "2     C  3.0  50000.0               62.0\n",
      "3     D  3.4  40000.0               67.0\n",
      "4     E  5.0  60000.0               98.0\n",
      "5     F  6.0  70000.0               21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praya\\AppData\\Local\\Temp\\ipykernel_9240\\3817170127.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Age\"].fillna(df[\"Age\"].mean(),inplace=True)\n",
      "C:\\Users\\praya\\AppData\\Local\\Temp\\ipykernel_9240\\3817170127.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Salary\"].fillna(df[\"Salary\"].mean(),inplace=True)\n",
      "C:\\Users\\praya\\AppData\\Local\\Temp\\ipykernel_9240\\3817170127.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Performance_Score\"].fillna(df[\"Performance_Score\"].mean(),inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\" : ['A',None,'C','D','E','F'],\n",
    "    \"Age\" : [1,2,3,None,5,6],\n",
    "    \"Salary\" : [50000,30000,None,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , None, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(\"Updated DataFrame\")\n",
    "df[\"Age\"].fillna(df[\"Age\"].mean(),inplace=True)\n",
    "# print(df[\"Salary\"].fillna(df[\"Salary\"].mean(),inplace=False))\n",
    "df[\"Salary\"].fillna(df[\"Salary\"].mean(),inplace=True)\n",
    "df[\"Performance_Score\"].fillna(df[\"Performance_Score\"].mean(),inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71cf37-9ccf-47b4-b0c8-4c5f90741fd3",
   "metadata": {},
   "source": [
    "# Filling Missing Values in the dataframe using linear method of interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292b6ca5-189f-46eb-b433-91622fb308eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age   Salary  Performance_Score\n",
      "0     A  1.0  50000.0               65.0\n",
      "1  None  2.0  30000.0               89.0\n",
      "2     C  3.0      NaN               62.0\n",
      "3     D  NaN  40000.0                NaN\n",
      "4     E  5.0  60000.0               98.0\n",
      "5     F  6.0  70000.0               21.0\n",
      "Modified : \n",
      "   Name  Age   Salary  Performance_Score\n",
      "0     A  1.0  50000.0               65.0\n",
      "1  None  2.0  30000.0               89.0\n",
      "2     C  3.0  35000.0               62.0\n",
      "3     D  4.0  40000.0               80.0\n",
      "4     E  5.0  60000.0               98.0\n",
      "5     F  6.0  70000.0               21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praya\\AppData\\Local\\Temp\\ipykernel_22324\\3655786885.py:16: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df.interpolate(method=\"linear\",axis=0,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# interpolate() --- we can use it to fill the missing values in any column or dataframe , it finds a extimate of the other values \n",
    "# Benefits of using this --- \n",
    "# 1- preserve data integrity\n",
    "# 2- smooth trends \n",
    "# 3- Avoid Data Loss \n",
    "\n",
    "#when to use interpolate():\n",
    "# 1- Timer Series Data \n",
    "# 2- numeric data with trends\n",
    "# 3- avoid dropping rows \n",
    "\n",
    "data = {\n",
    "    \"Name\" : ['A',None,'C','D','E','F'],\n",
    "    \"Age\" : [1,2,3,None,5,6],\n",
    "    \"Salary\" : [50000,30000,None,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , None, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(\"Modified : \")\n",
    "df.interpolate(method=\"linear\",axis=0,inplace=True)\n",
    "print(df)\n",
    "\n",
    "# There are some types of methods : \n",
    "# 1- linear \n",
    "# 2- polynomial\n",
    "# 3- time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1791d-69ec-4fe0-b307-434ad0a55997",
   "metadata": {},
   "source": [
    "# Sorting & Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9122d-9754-421c-93a6-5cacd9ba0c13",
   "metadata": {},
   "source": [
    "## Sorting Data 1 Column sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa7a966-c8de-41ac-bb01-b7658e973e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Age  Salary  Performance_Score\n",
      "0    A    1   50000                 65\n",
      "1    G    2   30000                 89\n",
      "2    C    3       0                 62\n",
      "3    D    8   40000                  0\n",
      "4    E    5   60000                 98\n",
      "5    F    6   70000                 21\n",
      "  Name  Age  Salary  Performance_Score\n",
      "0    A    1   50000                 65\n",
      "2    C    3       0                 62\n",
      "3    D    8   40000                  0\n",
      "4    E    5   60000                 98\n",
      "5    F    6   70000                 21\n",
      "1    G    2   30000                 89\n",
      "  Name  Age  Salary  Performance_Score\n",
      "1    G    2   30000                 89\n",
      "5    F    6   70000                 21\n",
      "4    E    5   60000                 98\n",
      "3    D    8   40000                  0\n",
      "2    C    3       0                 62\n",
      "0    A    1   50000                 65\n"
     ]
    }
   ],
   "source": [
    "# df.sort_values(by=\"Column Name\",ascending = True/False,inplace=True) ---> true means ascending order , false means desending order.\n",
    "\n",
    "data = {\n",
    "    \"Name\" : ['A','G','C','D','E','F'],\n",
    "    \"Age\" : [1,2,3,8,5,6],\n",
    "    \"Salary\" : [50000,30000,000,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , 00, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "df.sort_values(by=\"Name\",ascending=True,inplace=True)\n",
    "print(df)\n",
    "df.sort_values(by=\"Name\",ascending=False,inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d4b71f-44cc-42de-ba42-6dd66521aaf8",
   "metadata": {},
   "source": [
    "## Sorting Data Multiple Column sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d437462a-878e-4803-b186-b05671076c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Age  Salary  Performance_Score\n",
      "0    A    1   50000                 65\n",
      "1    G    2   30000                 89\n",
      "2    C    3       0                 62\n",
      "3    D    8   40000                  0\n",
      "4    E    5   60000                 98\n",
      "5    F    6   70000                 21\n",
      "  Name  Age  Salary  Performance_Score\n",
      "3    D    8   40000                  0\n",
      "5    F    6   70000                 21\n",
      "4    E    5   60000                 98\n",
      "2    C    3       0                 62\n",
      "1    G    2   30000                 89\n",
      "0    A    1   50000                 65\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\" : ['A','G','C','D','E','F'],\n",
    "    \"Age\" : [1,2,3,8,5,6],\n",
    "    \"Salary\" : [50000,30000,000,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , 00, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "df.sort_values(by=[\"Age\",\"Name\"],ascending=[False,True],inplace=True)  # here we have to pass the multiple values in the list.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b15a3b5-95ca-446e-bc11-dd516a23e4cf",
   "metadata": {},
   "source": [
    "# Aggregation--- > sum() , min() , max() , count() ... etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a184ed5f-032a-4a27-88a6-9dcea5c2eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Age  Salary  Performance_Score\n",
      "0    A    1   50000                 65\n",
      "1    G    2   30000                 89\n",
      "2    C    3       0                 62\n",
      "3    D    8   40000                  0\n",
      "4    E    5   60000                 98\n",
      "5    F    6   70000                 21\n",
      "25\n",
      "6\n",
      "1\n",
      "8\n",
      "4.166666666666667\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\" : ['A','G','C','D','E','F'],\n",
    "    \"Age\" : [1,2,3,8,5,6],\n",
    "    \"Salary\" : [50000,30000,000,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , 00, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(df[\"Age\"].sum())\n",
    "print(df[\"Age\"].count())\n",
    "print(df[\"Age\"].min())\n",
    "print(df[\"Age\"].max())\n",
    "print(df[\"Age\"].mean())\n",
    "# ETC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab192f2c-0c34-4090-9e03-49d0ad299ad7",
   "metadata": {},
   "source": [
    "# Grouping Of Data and using of Aggregation methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eb75f6d-ea6a-4b84-b6ff-92a3be80b4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Age  Salary  Performance_Score\n",
      "0    A    1   50000                 65\n",
      "1    G    2   30000                 89\n",
      "2    C    3       0                 62\n",
      "3    D    8   40000                  0\n",
      "4    E    5   60000                 98\n",
      "5    F    6   70000                 21\n",
      "Age\n",
      "1    50000.0\n",
      "2    30000.0\n",
      "3        0.0\n",
      "5    60000.0\n",
      "6    70000.0\n",
      "8    40000.0\n",
      "Name: Salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# using groupby(\"Column Name\")[\"Column Name 2 \"]                       ---> (\"ColumnName\") is the grouping column \n",
    "data = {                                  #                            ---> [\"Column Name 2 \"] is the \n",
    "    \"Name\" : ['A','G','C','D','E','F'],\n",
    "    \"Age\" : [1,2,3,8,5,6],\n",
    "    \"Salary\" : [50000,30000,000,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , 00, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "grouped= df.groupby(\"Age\")[\"Salary\"].mean()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3237209-05da-4d01-9579-b02108da8069",
   "metadata": {},
   "source": [
    "# Grouping Multiple Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc8e1e5-87a1-41c5-9c28-cd59a5d91522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Age  Salary  Performance_Score\n",
      "0    A    1   50000                 65\n",
      "1    G    2   30000                 89\n",
      "2    C    3       0                 62\n",
      "3    D    8   40000                  0\n",
      "4    E    5   60000                 98\n",
      "5    F    6   70000                 21\n",
      "Age  Name\n",
      "1    A       50000\n",
      "2    G       30000\n",
      "3    C           0\n",
      "5    E       60000\n",
      "6    F       70000\n",
      "8    D       40000\n",
      "Name: Salary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# using groupby([\"Column Name\",\"Column Name ])[\"Column Name 2 \"]       ---> [\"Col Name\",\"Col name \"] here we are giving it as a list to group multiple columns\n",
    "data = {                                  #                            ---> [\"Column Name 2 \"] is the operation we have to preform \n",
    "    \"Name\" : ['A','G','C','D','E','F'],\n",
    "    \"Age\" : [1,2,3,8,5,6],\n",
    "    \"Salary\" : [50000,30000,000,40000,60000,70000],\n",
    "    \"Performance_Score\" : [ 65,89 ,62 , 00, 98, 21]    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "grouped= df.groupby([\"Age\",\"Name\"])[\"Salary\"].sum()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d5565-faef-48c8-8c48-fc5b4d9df237",
   "metadata": {},
   "source": [
    "# Merging & Joining  --- using inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515005b5-f397-4caf-b090-a785ef588fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Joined : \n",
      "   CustomerId    Name  OrderAmount\n",
      "0           1  Ashwin          456\n",
      "1           2     Ash          576\n"
     ]
    }
   ],
   "source": [
    "# df.merge( df1 , df2 , on = \"Column_Name\" , how = \"Type of Join \" )\n",
    "\n",
    "df_customer = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,3],\n",
    "    'Name' : [\"Ashwin\",\"Ash\",\"Serina\"]\n",
    "})\n",
    "\n",
    "df_order = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,4],\n",
    "    'OrderAmount' : [456,576,887]\n",
    "})\n",
    "\n",
    "# Merged \n",
    "df_merge = pd.merge(df_customer,df_order,on=\"CustomerId\",how = \"inner\")\n",
    "print(\"Inner Joined : \")\n",
    "print(df_merge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba3c3d2-771e-45d8-97b2-c8ac3fff33f2",
   "metadata": {},
   "source": [
    "# Merging & Joining  --- using outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f371ec-4b8d-4043-867d-0f9f06c1c4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Joined : \n",
      "   CustomerId    Name  OrderAmount\n",
      "0           1  Ashwin        456.0\n",
      "1           2     Ash        576.0\n",
      "2           3  Serina          NaN\n",
      "3           4     NaN        887.0\n"
     ]
    }
   ],
   "source": [
    "df_customer = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,3],\n",
    "    'Name' : [\"Ashwin\",\"Ash\",\"Serina\"]\n",
    "})\n",
    "\n",
    "df_order = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,4],\n",
    "    'OrderAmount' : [456,576,887]\n",
    "})\n",
    "\n",
    "# Merged \n",
    "df_merge = pd.merge(df_customer,df_order,on=\"CustomerId\",how = \"outer\")\n",
    "print(\"Outer Joined : \")\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85390515-350b-4dca-90fc-a6126827ac23",
   "metadata": {},
   "source": [
    "# Merging & Joining  --- using Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ede21c4-0168-4451-b038-80d1660584b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Joined : \n",
      "   CustomerId    Name  OrderAmount\n",
      "0           1  Ashwin        456.0\n",
      "1           2     Ash        576.0\n",
      "2           3  Serina          NaN\n"
     ]
    }
   ],
   "source": [
    "df_customer = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,3],\n",
    "    'Name' : [\"Ashwin\",\"Ash\",\"Serina\"]\n",
    "})\n",
    "\n",
    "df_order = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,4],\n",
    "    'OrderAmount' : [456,576,887]\n",
    "})\n",
    "\n",
    "# Merged \n",
    "df_merge = pd.merge(df_customer,df_order,on=\"CustomerId\",how = \"left\")\n",
    "print(\"Left Joined : \")\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c809640-a9c5-4c2d-9b7d-e0c10fda7b48",
   "metadata": {},
   "source": [
    "# Merging & Joining  --- using Right Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7accaee-4874-4894-9d32-8e4b0b52af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Joined : \n",
      "   CustomerId    Name  OrderAmount\n",
      "0           1  Ashwin          456\n",
      "1           2     Ash          576\n",
      "2           4     NaN          887\n"
     ]
    }
   ],
   "source": [
    "df_customer = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,3],\n",
    "    'Name' : [\"Ashwin\",\"Ash\",\"Serina\"]\n",
    "})\n",
    "\n",
    "df_order = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,4],\n",
    "    'OrderAmount' : [456,576,887]\n",
    "})\n",
    "\n",
    "# Merged \n",
    "df_merge = pd.merge(df_customer,df_order,on=\"CustomerId\",how = \"right\")\n",
    "print(\"Right Joined : \")\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ddab0-c48a-457d-9beb-db56d5531151",
   "metadata": {},
   "source": [
    "# Merging & Joining  --- using Cross Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a68f2a0-c74d-4e99-9fc2-1d560cc045e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Joined : \n",
      "   CustomerId_x    Name  CustomerId_y  OrderAmount\n",
      "0             1  Ashwin             1          456\n",
      "1             1  Ashwin             2          576\n",
      "2             1  Ashwin             4          887\n",
      "3             2     Ash             1          456\n",
      "4             2     Ash             2          576\n",
      "5             2     Ash             4          887\n",
      "6             3  Serina             1          456\n",
      "7             3  Serina             2          576\n",
      "8             3  Serina             4          887\n"
     ]
    }
   ],
   "source": [
    "df_customer = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,3],\n",
    "    'Name' : [\"Ashwin\",\"Ash\",\"Serina\"]\n",
    "})\n",
    "\n",
    "df_order = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,4],\n",
    "    'OrderAmount' : [456,576,887]\n",
    "})\n",
    "\n",
    "# Merged \n",
    "df_merge = pd.merge(df_customer,df_order,how = \"cross\")\n",
    "print(\"Cross Joined : \")\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474de24-f496-4c88-a30e-03bb2d592b82",
   "metadata": {},
   "source": [
    "# Concating DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67e6b2ae-aaf4-4824-a5eb-b7aec754354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerId    Name  OrderAmount\n",
      "0           1  Ashwin          NaN\n",
      "1           2     Ash          NaN\n",
      "2           3  Serina          NaN\n",
      "3           1     NaN        456.0\n",
      "4           2     NaN        576.0\n",
      "5           4     NaN        887.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Vertically (Row-Wise)\n",
    "HoriZontally (Column-Wise)\n",
    "\n",
    "pd.concat([df1,df2],axis= 0 , ignore_index=True )\n",
    "\n",
    "[df1,df2]  --> passing dataframe as the list..\n",
    "axis = 0 (Row Wise Concation )\n",
    "axis = 1 (Column Wise concation )\n",
    "\n",
    "ignore_index = True --> That means it will ignore the default dataframes indexs and make a new one in the concated dataframe\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_customer = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,3],\n",
    "    'Name' : [\"Ashwin\",\"Ash\",\"Serina\"]\n",
    "})\n",
    "\n",
    "df_order = pd.DataFrame({\n",
    "    'CustomerId' : [1,2,4],\n",
    "    'OrderAmount' : [456,576,887]\n",
    "})\n",
    "\n",
    "# CONCATE\n",
    "\n",
    "df_concate = pd.concat([df_customer,df_order],axis=0,ignore_index = True)\n",
    "print(df_concate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114a9c8-ce09-4202-bae9-cb1ad9cfcc3b",
   "metadata": {},
   "source": [
    "# So Now The Pandas Is Finished .We Will Move Forward To The Projects Now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
